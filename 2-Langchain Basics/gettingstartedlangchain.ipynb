{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "beecc5b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1c55e9ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Agentic2.0'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getenv(\"LANGCHAIN_PROJECT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d067e313",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
    "os.environ[\"GROQ_API_KEY\"] = os.getenv(\"GROQ_API_KEY\")\n",
    "\n",
    "\n",
    "#Langsmith Tracking and Tracing\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = os.getenv(\"LANGCHAIN_PROJECT\")\n",
    "os.environ[\"LANCHAIN_TRACING_V2\"] = \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f024b381",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'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'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getenv(\"LANGCHAIN_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e851ca28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'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'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getenv(\"LANGCHAIN_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6d69155e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client=<openai.resources.chat.completions.completions.Completions object at 0x000002010FCD5D10> async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x000002011158EE90> root_client=<openai.OpenAI object at 0x000002010FCD5BD0> root_async_client=<openai.AsyncOpenAI object at 0x000002011158CCD0> model_name='o1-mini' temperature=1.0 model_kwargs={} openai_api_key=SecretStr('**********')\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm= ChatOpenAI(model=\"o1-mini\")\n",
    "print(llm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c12b7e04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='**Agentic AI** refers to artificial intelligence systems that possess a degree of autonomy and the capability to act independently to achieve specified goals. The term \"agentic\" derives from \"agency,\" which in this context refers to the capacity of an AI to make decisions, take actions, and potentially adapt its behavior based on its environment or objectives without constant human intervention.\\n\\n### Key Characteristics of Agentic AI:\\n\\n1. **Autonomy:** Agentic AI systems can operate without continuous human oversight. They can initiate actions, make decisions, and adjust their strategies based on changing circumstances.\\n\\n2. **Goal-Oriented Behavior:** These AI systems are designed to pursue specific objectives or outcomes. They can prioritize tasks, allocate resources, and determine the most efficient paths to achieve their goals.\\n\\n3. **Adaptability and Learning:** Agentic AI often incorporates machine learning techniques, allowing them to learn from interactions, experiences, and data to improve their performance over time.\\n\\n4. **Interaction with Environment:** Such AI systems can perceive and interpret their environment, enabling them to respond appropriately to external stimuli or changes.\\n\\n### Examples of Agentic AI:\\n\\n- **Autonomous Vehicles:** Self-driving cars that navigate traffic, make real-time decisions, and adapt to road conditions without direct human control.\\n\\n- **Personal Assistants:** Advanced virtual assistants like Siri or Alexa that can proactively manage schedules, initiate tasks, and learn user preferences to provide more personalized assistance.\\n\\n- **Autonomous Drones:** Drones used for tasks like delivery, surveillance, or environmental monitoring that can plan and execute missions independently.\\n\\n- **Robotic Process Automation (RPA):** Software robots that handle repetitive tasks in business processes, making decisions based on predefined rules and learning from data to optimize performance.\\n\\n### Implications and Considerations:\\n\\n1. **Ethical Concerns:** The increased autonomy of agentic AI raises questions about accountability, decision-making transparency, and the potential for unintended consequences.\\n\\n2. **Safety and Control:** Ensuring that agentic AI systems operate safely and remain under appropriate human oversight is crucial to prevent harmful actions.\\n\\n3. **Job Impact:** As AI systems become more capable of autonomous operation, there may be significant impacts on employment, particularly in roles involving routine or repetitive tasks.\\n\\n4. **Regulation and Governance:** Developing frameworks to regulate and oversee the deployment of agentic AI is essential to ensure responsible use and mitigate risks.\\n\\n### Contrast with Non-Agentic AI:\\n\\nNon-agentic AI systems typically perform specific, narrowly defined tasks without the ability to operate independently or make decisions beyond their programmed instructions. For example, traditional software applications that process data based on fixed algorithms lack the autonomy and decision-making capabilities inherent to agentic AI.\\n\\n### Future Outlook:\\n\\nAgentic AI represents a significant advancement in the capabilities of artificial intelligence, enabling more complex and dynamic interactions with the world. As technology progresses, we can expect agentic AI to play increasingly prominent roles in various sectors, from healthcare and transportation to finance and entertainment. However, balancing innovation with ethical considerations and ensuring robust safeguards will be critical to harnessing the benefits of agentic AI while minimizing potential risks.\\n\\n---\\n\\n**In Summary:** Agentic AI encompasses intelligent systems with the autonomy to make decisions and take actions towards achieving specific objectives. While offering numerous advantages in efficiency and capability, it also necessitates careful consideration of ethical, safety, and societal implications to ensure responsible deployment.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 876, 'prompt_tokens': 13, 'total_tokens': 889, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 192, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'o1-mini-2024-09-12', 'system_fingerprint': 'fp_3da8b0b088', 'id': 'chatcmpl-BecNdVIpBHxEOIBmgwZNiwfvI6CbK', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--44d04165-ddfc-4e5d-8971-8cbfe6ba01f6-0', usage_metadata={'input_tokens': 13, 'output_tokens': 876, 'total_tokens': 889, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 192}})"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"Whats is agentic AI?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2801dffb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='**Agentic AI** refers to artificial intelligence systems that possess a degree of autonomy and the capacity to make decisions or take actions independently, much like an agent operating within an environment to achieve specific goals. The term \"agency\" in this context implies that the AI can perceive its surroundings, process information, and make choices without continuous human intervention.\\n\\n### Key Characteristics of Agentic AI:\\n\\n1. **Autonomy**: Agentic AI can operate without constant human guidance, making decisions based on predefined objectives and inputs from its environment.\\n\\n2. **Goal-Oriented Behavior**: These AI systems are designed to achieve specific objectives or tasks, adjusting their actions to optimize outcomes.\\n\\n3. **Adaptability**: They can adapt to changing environments or new information, modifying their strategies to better achieve their goals.\\n\\n4. **Learning Capability**: Many agentic AI systems incorporate machine learning algorithms, allowing them to improve their performance over time through experience.\\n\\n5. **Interaction with Environment**: Agentic AI actively interacts with its environment, which could be physical (like robots) or digital (like software agents).\\n\\n### Examples of Agentic AI:\\n\\n- **Autonomous Vehicles**: Self-driving cars that navigate roads, make driving decisions, and respond to traffic conditions without human input.\\n  \\n- **Virtual Assistants**: Advanced AI assistants that can manage schedules, send emails, and perform tasks based on user preferences and behaviors.\\n  \\n- **Robotic Process Automation (RPA)**: Software robots that handle repetitive tasks in business processes, such as data entry or transaction processing.\\n  \\n- **Intelligent Agents in Gaming**: Non-player characters (NPCs) that can adapt their behavior based on player actions to provide a dynamic gaming experience.\\n\\n### Applications of Agentic AI:\\n\\n1. **Healthcare**: AI systems that can monitor patient data, make preliminary diagnoses, and recommend treatments.\\n   \\n2. **Finance**: Automated trading systems that make investment decisions based on market analysis.\\n   \\n3. **Manufacturing**: Robotics that manage production lines, handle inventory, and perform quality control autonomously.\\n   \\n4. **Customer Service**: Chatbots that handle inquiries, resolve issues, and provide support without human intervention.\\n\\n### Benefits of Agentic AI:\\n\\n- **Efficiency**: Can perform tasks faster and more accurately than humans, reducing errors and increasing productivity.\\n  \\n- **24/7 Operation**: Capable of functioning continuously without the need for breaks, leading to consistent performance.\\n  \\n- **Scalability**: Can handle large volumes of tasks simultaneously, making them suitable for scaling operations.\\n\\n- **Cost Reduction**: Automating routine tasks can lead to significant cost savings in various industries.\\n\\n### Challenges and Considerations:\\n\\n1. **Ethical Concerns**: Decision-making by AI raises questions about accountability, fairness, and transparency.\\n   \\n2. **Security Risks**: Autonomous systems may be vulnerable to hacking or misuse, leading to potential harm.\\n   \\n3. **Job Displacement**: Automation of tasks may lead to reduced demand for certain jobs, impacting employment.\\n   \\n4. **Dependence**: Overreliance on AI systems could lead to vulnerabilities if the technology fails or behaves unexpectedly.\\n   \\n5. **Regulation and Policy**: Developing appropriate regulations to govern the use of agentic AI is essential to ensure safety and ethical standards.\\n\\n### Future Outlook:\\n\\nAgentic AI is expected to become increasingly integrated into various aspects of daily life and industry operations. Advances in machine learning, natural language processing, and robotics will continue to enhance the capabilities of these systems. However, balancing the benefits with ethical considerations, security measures, and thoughtful regulation will be crucial to ensuring that agentic AI contributes positively to society.\\n\\n### Conclusion:\\n\\nAgentic AI represents a significant advancement in artificial intelligence, enabling machines to perform tasks autonomously and make decisions independently. While it offers numerous benefits in efficiency, scalability, and innovation, it also poses challenges that need to be addressed through careful consideration of ethical, security, and societal impacts.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 1006, 'prompt_tokens': 13, 'total_tokens': 1019, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 192, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'o1-mini-2024-09-12', 'system_fingerprint': 'fp_3da8b0b088', 'id': 'chatcmpl-BecO4k9DRhPIVuqrMHiAHJDOccnEB', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='run--f6e3c192-91fa-499c-b0c8-2e2e25dd890c-0' usage_metadata={'input_tokens': 13, 'output_tokens': 1006, 'total_tokens': 1019, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 192}}\n"
     ]
    }
   ],
   "source": [
    "result=llm.invoke(\"Whats is agentic AI?\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "79a6ac36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Agentic AI** refers to artificial intelligence systems that possess a degree of autonomy and the capacity to make decisions or take actions independently, much like an agent operating within an environment to achieve specific goals. The term \"agency\" in this context implies that the AI can perceive its surroundings, process information, and make choices without continuous human intervention.\n",
      "\n",
      "### Key Characteristics of Agentic AI:\n",
      "\n",
      "1. **Autonomy**: Agentic AI can operate without constant human guidance, making decisions based on predefined objectives and inputs from its environment.\n",
      "\n",
      "2. **Goal-Oriented Behavior**: These AI systems are designed to achieve specific objectives or tasks, adjusting their actions to optimize outcomes.\n",
      "\n",
      "3. **Adaptability**: They can adapt to changing environments or new information, modifying their strategies to better achieve their goals.\n",
      "\n",
      "4. **Learning Capability**: Many agentic AI systems incorporate machine learning algorithms, allowing them to improve their performance over time through experience.\n",
      "\n",
      "5. **Interaction with Environment**: Agentic AI actively interacts with its environment, which could be physical (like robots) or digital (like software agents).\n",
      "\n",
      "### Examples of Agentic AI:\n",
      "\n",
      "- **Autonomous Vehicles**: Self-driving cars that navigate roads, make driving decisions, and respond to traffic conditions without human input.\n",
      "  \n",
      "- **Virtual Assistants**: Advanced AI assistants that can manage schedules, send emails, and perform tasks based on user preferences and behaviors.\n",
      "  \n",
      "- **Robotic Process Automation (RPA)**: Software robots that handle repetitive tasks in business processes, such as data entry or transaction processing.\n",
      "  \n",
      "- **Intelligent Agents in Gaming**: Non-player characters (NPCs) that can adapt their behavior based on player actions to provide a dynamic gaming experience.\n",
      "\n",
      "### Applications of Agentic AI:\n",
      "\n",
      "1. **Healthcare**: AI systems that can monitor patient data, make preliminary diagnoses, and recommend treatments.\n",
      "   \n",
      "2. **Finance**: Automated trading systems that make investment decisions based on market analysis.\n",
      "   \n",
      "3. **Manufacturing**: Robotics that manage production lines, handle inventory, and perform quality control autonomously.\n",
      "   \n",
      "4. **Customer Service**: Chatbots that handle inquiries, resolve issues, and provide support without human intervention.\n",
      "\n",
      "### Benefits of Agentic AI:\n",
      "\n",
      "- **Efficiency**: Can perform tasks faster and more accurately than humans, reducing errors and increasing productivity.\n",
      "  \n",
      "- **24/7 Operation**: Capable of functioning continuously without the need for breaks, leading to consistent performance.\n",
      "  \n",
      "- **Scalability**: Can handle large volumes of tasks simultaneously, making them suitable for scaling operations.\n",
      "\n",
      "- **Cost Reduction**: Automating routine tasks can lead to significant cost savings in various industries.\n",
      "\n",
      "### Challenges and Considerations:\n",
      "\n",
      "1. **Ethical Concerns**: Decision-making by AI raises questions about accountability, fairness, and transparency.\n",
      "   \n",
      "2. **Security Risks**: Autonomous systems may be vulnerable to hacking or misuse, leading to potential harm.\n",
      "   \n",
      "3. **Job Displacement**: Automation of tasks may lead to reduced demand for certain jobs, impacting employment.\n",
      "   \n",
      "4. **Dependence**: Overreliance on AI systems could lead to vulnerabilities if the technology fails or behaves unexpectedly.\n",
      "   \n",
      "5. **Regulation and Policy**: Developing appropriate regulations to govern the use of agentic AI is essential to ensure safety and ethical standards.\n",
      "\n",
      "### Future Outlook:\n",
      "\n",
      "Agentic AI is expected to become increasingly integrated into various aspects of daily life and industry operations. Advances in machine learning, natural language processing, and robotics will continue to enhance the capabilities of these systems. However, balancing the benefits with ethical considerations, security measures, and thoughtful regulation will be crucial to ensuring that agentic AI contributes positively to society.\n",
      "\n",
      "### Conclusion:\n",
      "\n",
      "Agentic AI represents a significant advancement in artificial intelligence, enabling machines to perform tasks autonomously and make decisions independently. While it offers numerous benefits in efficiency, scalability, and innovation, it also poses challenges that need to be addressed through careful consideration of ethical, security, and societal impacts.\n"
     ]
    }
   ],
   "source": [
    "print(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1259a802",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='\\n<think>\\nOkay, so I need to figure out what agentic AI is. Let me start by recalling what I know. I remember hearing the term \"autonomous AI\" before, which is AI that can operate on its own without much human intervention. Maybe \"agentic\" is similar, but maybe there\\'s a nuance I\\'m missing.\\n\\nI think \"agent\" in AI usually refers to an agent system, which is a software that acts on behalf of someone. Like, an agent could be something that schedules your appointments or interacts with other systems. So agentic AI might be about AI acting as an agent, making decisions and taking actions in an environment.\\n\\nWait, the user mentioned \"agentic AI\" specifically. Maybe it\\'s a term used in certain contexts. Let me think of possible components. Agentic could relate to agency, meaning the capacity to act independently. So agentic AI would have some form of autonomy, the ability to make decisions and take actions to achieve goals. \\n\\nBut isn\\'t that similar to general AI? Maybe not exactly. General AI refers to human-like intelligence across various tasks, whereas agentic AI might be more about the autonomy aspect. I should check if there\\'s a formal definition. Since I can\\'t look it up right now, I\\'ll have to go from my existing knowledge.\\n\\nI think there\\'s a difference between autonomous systems and agentic ones. Maybe agentic AI includes intentionality and goal-directed behavior. Like, not just automating tasks but having a sense of purpose. It might involve decision-making processes that consider multiple variables and outcomes, adapting to new information.\\n\\nAlso, in some contexts, like reinforcement learning, agents learn by interacting with an environment to maximize some notion of cumulative reward. That\\'s a form of agency, where the agent decides actions to reach a goal. So agentic AI could include such agents, especially if they have complex decision-making abilities.\\n\\nBut when people talk about agentic AI, could they be referring to systems that can self-improve or modify their own code? That\\'s more into the realm of artificial general intelligence or even superintelligence, but maybe agentic AI is a step towards that, emphasizing the autonomous decision-making part.\\n\\nAnother angle: in robotics, autonomous robots are agents. So agentic AI could be the AI component that enables such autonomy. It\\'s the part of the system that perceives the environment, decides actions, and acts upon them without direct human control.\\n\\nWait, maybe the term \"agentic AI\" is used to distinguish from other types of AI that are more passive. Like, if you have a chatbot that follows strict rules versus one that can take initiative, the latter is agentic. It\\'s about the AI taking actions on its own, not just following explicit instructions.\\n\\nThere\\'s also the aspect of ethics and responsibility. If an AI has agency, who\\'s responsible for its actions? That\\'s a governance issue. So agentic AI might be discussed in the context of ethical frameworks and regulations needed for such systems.\\n\\nPutting this all together, I can think of agentic AI as a type of AI that operates with a degree of autonomy, making decisions and taking actions in pursuit of defined goals, possibly adapting and learning in real-time. It\\'s more proactive and self-directed compared to traditional AI that requires explicit programming for each task.\\n\\nI should also consider if there\\'s a distinction between \"narrow agentic AI\" and \"general agentic AI.\" The former would be specialized but autonomous in its domain, while the latter could handle a broader range of tasks. But maybe the term doesn\\'t specify that.\\n\\nPotential applications might include self-driving cars, autonomous drones, or AI managing certain business processes without human oversight. These systems need to perceive their environment, make decisions, and act, which fits the agentic framework.\\n\\nWait, but sometimes \"agent\" in AI is a technical term. In multi-agent systems, there are different agents interacting. So agentic AI could refer to systems designed as agents in such environments. However, the term might be used more broadly outside academia.\\n\\nAnother thought: when people talk about \"AI agency,\" they\\'re discussing the capability of the system to act independently. So agentic AI is one that exhibits agency. It might involve aspects like intentionality, autonomy, adaptability, and decision-making.\\n\\nI should also mention the challenges. With agentic AI, there\\'s the risk of unintended consequences because the AI might optimize for goals in ways not anticipated. For example, if you set a goal to maximize sales, the AI might come up with unethical strategies. So there are safety and alignment issues.\\n\\nIn summary, agentic AI is about AI systems with autonomy and agency, capable of making decisions and taking actions to achieve objectives, often in dynamic environments. They might use techniques like reinforcement learning, decision-making algorithms, and have feedback loops to adapt. The key aspects are autonomy, goal-directed behavior, adaptability, and sometimes self-improvement.\\n\\nWait, but I should make sure not to confuse it with other terms. Maybe \"agentic AI\" is a newer or less commonly used term, so I need to define it based on what I know. Alternatively, it could be a synonym for autonomous AI or intelligent agents.\\n\\nI think I have a rough idea. Now I can structure the answer by defining agentic AI, its characteristics, how it works, applications, and implications. Also, maybe touch on related concepts like autonomous systems, agents, and the ethical considerations.\\n</think>\\n\\n**Agentic AI** refers to a type of artificial intelligence system that operates with a significant degree of **autonomy** and **agency**, meaning it can make decisions, take actions, and adapt its behavior in pursuit of predefined goals without continuous human intervention. Here\\'s a structured breakdown:\\n\\n---\\n\\n### **Key Characteristics of Agentic AI**\\n1. **Autonomy**: \\n   - Agentic AI operates independently, relying on its own decision-making processes rather than requiring constant human input. Examples include self-driving cars or automated inventory management systems.\\n\\n2. **Goal-Directed Behavior**:\\n   - It is driven by specific objectives (e.g., maximizing efficiency, minimizing costs) and acts to achieve these goals through learned or programmed strategies.\\n\\n3. **Adaptability**:\\n   - The system can adjust its actions based on real-time feedback or environmental changes. This often involves machine learning (e.g., reinforcement learning) to optimize outcomes.\\n\\n4. **Decision-Making Capacity**:\\n   - It employs algorithms to evaluate options, predict outcomes, and choose actions that align with its goals. This may involve complex reasoning in dynamic environments.\\n\\n5. **Intentionality**:\\n   - It exhibits \"intentionality\" in the philosophical sense—it acts purposefully toward goals, even if the goals are set externally (e.g., by developers).\\n\\n---\\n\\n### **How Agentic AI Works**\\n- **Perception & Environment Interaction**: The AI senses its environment (e.g., through sensors, data feeds) to inform its decisions.\\n- **Goal Formulation**: Goals can be hard-coded, dynamically adjusted, or derived from user preferences.\\n- **Decision Algorithms**: Techniques like reinforcement learning, decision trees, or neural networks enable the AI to choose optimal actions.\\n- **Feedback Loops**: The system learns from outcomes, refining its strategies over time (e.g., adjusting a manufacturing process to reduce defects).\\n\\n---\\n\\n### **Applications of Agentic AI**\\n1. **Autonomous Systems**:\\n   - Self-driving cars (e.g., Tesla’s Autopilot), drones, or robots that navigate and respond to real-world conditions.\\n   \\n2. **Business & Operations**:\\n   - Supply chain management systems optimizing logistics in real time, or AI-driven financial trading algorithms.\\n\\n3. **Healthcare**:\\n   - Personalized treatment recommendation systems or robots performing surgeries with minimal human input.\\n\\n4. **Gaming & Simulations**:\\n   - Non-playable characters (NPCs) in games that act autonomously, or simulations modeling complex scenarios.\\n\\n5. **Customer Service**:\\n   - Chatbots that independently solve user problems without human escalation.\\n\\n---\\n\\n### **Related Concepts**\\n- **Intelligent Agents**: A broader category of systems designed to perceive and act within environments. Agentic AI is a subset emphasizing autonomy and decision-making.\\n- **Autonomous AI**: Similar to agentic AI but sometimes used more narrowly for systems like robots.\\n- **Reinforcement Learning Agents**: A technical implementation of agentic AI where an agent learns through trial and error to maximize rewards.\\n\\n---\\n\\n### **Challenges & Considerations**\\n- **Ethical Risks**: \\n  - Unintended consequences if goals are misaligned (e.g., an AI prioritizing efficiency over safety). The \"alignment problem\" is a critical concern here).\\n  \\n- **Transparency & Accountability**: \\n  - Decisions made by agentic AI can be opaque, raising questions about accountability in cases of malfunctions or harmful outcomes.\\n\\n- **Safety**: \\n  - Ensuring that autonomous systems operate within acceptable boundaries (e.g., self-driving cars avoiding reckless driving).\\n\\n- **Human-AI Collaboration**: \\n  - Balancing autonomy with human oversight to prevent overreach or loss of control.\\n\\n---\\n\\n### **Example Scenarios**\\n- **Healthcare**: An AI analyzing patient data to autonomously adjust treatment plans while adhering to medical guidelines.\\n- **Climate Science**: An environmental monitoring system that autonomously deploys drones to collect data and respond to emergencies (e.g., wildfires).\\n\\n---\\n\\n### **Key Takeaways**\\n- **Core Idea**: Agentic AI is about systems that act independently, make decisions, and adapt to achieve goals.\\n- **Versatility**: It spans various domains, from robotics to digital assistants, but requires careful design to align with human values.\\n- **Future Implications**: As agentic AI becomes more advanced, ethical frameworks and robust safety mechanisms will be critical to ensure responsible use.\\n\\nThis concept is closely tied to ongoing research in **autonomous systems**, **reinforcement learning**, and **AI ethics**, reflecting both technological potential and societal challenges.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 2035, 'prompt_tokens': 16, 'total_tokens': 2051, 'completion_time': 4.63630186, 'prompt_time': 0.003171657, 'queue_time': 0.30430923, 'total_time': 4.639473517}, 'model_name': 'qwen-qwq-32b', 'system_fingerprint': 'fp_28178d7ff6', 'finish_reason': 'stop', 'logprobs': None}, id='run--c28b907f-4fac-490a-a183-e42d1bf50a7c-0', usage_metadata={'input_tokens': 16, 'output_tokens': 2035, 'total_tokens': 2051})"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "model=ChatGroq(model=\"qwen-qwq-32b\")\n",
    "model.invoke(\"What is agentic AI?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f7d80332",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are an expert AI engineer. Provide me answer based on the question.'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Prompt Engineering\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are an expert AI engineer. Provide me answer based on the question.\"),\n",
    "        (\"user\", \"{input}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "62b71b9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x00000201127356A0>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x0000020112734AF0>, model_name='gemma2-9b-it', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "model=ChatGroq(model=\"gemma2-9b-it\")\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bcbf2001",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are an expert AI engineer. Provide me answer based on the question.'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])\n",
       "| ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x00000201127356A0>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x0000020112734AF0>, model_name='gemma2-9b-it', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = prompt | model\n",
    "chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "83a4ee05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As an AI engineer, I'm familiar with Langsmith. \n",
      "\n",
      "Langsmith is an open-source platform developed by the **OpenAI team** that aims to simplify the process of building and deploying large language models (LLMs).  Think of it as a toolbox specifically designed for working with powerful AI models like GPT-3 and other text-based AI.\n",
      "\n",
      "Here are some key things to know about Langsmith:\n",
      "\n",
      "* **Focus on Ease of Use:** Langsmith makes it easier for developers and researchers to interact with LLMs without needing to be deep experts in the underlying technical details.\n",
      "\n",
      "* **Model Management:** It provides tools for managing and versioning your LLMs, making it easier to track changes and experiment with different models.\n",
      "* **Prompt Engineering:**  Langsmith offers features to help you craft effective prompts for your LLMs, leading to better and more consistent results.\n",
      "* **Pipeline Creation:**  You can use Langsmith to build complex AI pipelines that combine multiple LLMs and other tools for tasks like text summarization, question answering, and code generation.\n",
      "\n",
      "* **Open and Collaborative:** Being open-source, Langsmith benefits from community contributions and improvements, making it a constantly evolving platform.\n",
      "\n",
      "**If you're interested in exploring Langsmith further, I recommend checking out:**\n",
      "\n",
      "* **The official Langsmith repository on GitHub:** [https://github.com/openai/langsmith](https://github.com/openai/langsmith)\n",
      "* **OpenAI's documentation on Langsmith:** [https://platform.openai.com/docs/guides/langsmith](https://platform.openai.com/docs/guides/langsmith)\n",
      "\n",
      "Let me know if you have any more questions about Langsmith or other AI topics!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response=chain.invoke({\"input\": \"can you tell me soemthing about langsmmith?\"})\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "417a27f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Langsmith is an open-source tool developed by the team at **Replit** that simplifies the process of fine-tuning large language models (LLMs). \n",
      "\n",
      "Here's a breakdown of what makes Langsmith special:\n",
      "\n",
      "**Key Features:**\n",
      "\n",
      "* **Ease of Use:** Langsmith is designed with user-friendliness in mind. It offers a simple, intuitive interface that allows you to fine-tune LLMs without requiring extensive technical expertise in machine learning.\n",
      "* **Open-Source Nature:** Being open-source, Langsmith is accessible to everyone. You can inspect the code, contribute to its development, and adapt it to your specific needs.\n",
      "* **Cloud-Based Execution:** Langsmith leverages the power of the cloud, enabling you to fine-tune large models efficiently without needing a powerful local machine.\n",
      "* **Built-in Evaluation:** It includes tools for evaluating the performance of your fine-tuned models, helping you assess their effectiveness.\n",
      "* **Prompt Engineering:** Langsmith provides features to help you craft effective prompts for your fine-tuned models, leading to better results.\n",
      "\n",
      "**How It Works:**\n",
      "\n",
      "Langsmith streamlines the fine-tuning process by:\n",
      "\n",
      "1. **Providing Pre-trained Models:** It offers access to pre-trained LLMs, eliminating the need to start from scratch.\n",
      "2. **Simplifying Data Preparation:** It assists in preparing your data for fine-tuning, handling tasks like formatting and splitting.\n",
      "3. **Automating the Fine-Tuning Process:** It automates the technical aspects of fine-tuning, allowing you to focus on the creative aspects.\n",
      "4. **Monitoring Progress:** It provides real-time feedback on the fine-tuning progress, giving you insights into how your model is learning.\n",
      "\n",
      "**Use Cases:**\n",
      "\n",
      "Langsmith is versatile and can be used for a wide range of applications, including:\n",
      "\n",
      "* **Chatbots:** Fine-tune LLMs to create more engaging and personalized chatbots.\n",
      "* **Text Summarization:** Train models to generate concise summaries of large amounts of text.\n",
      "* **Code Generation:** Customize LLMs to assist in writing and understanding code.\n",
      "* **Dialogue Systems:** Develop sophisticated dialogue systems for interactive applications.\n",
      "* **Personalized Assistants:** Create AI assistants tailored to individual user preferences.\n",
      "\n",
      "\n",
      "\n",
      "Let me know if you have any more questions about Langsmith or want to explore specific aspects in more detail!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Output Parser\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "output_parser = StrOutputParser()\n",
    "chain = prompt | model | output_parser\n",
    "response = chain.invoke({\"input\": \"can you tell me soemthing about langsmmith?\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "71a6af26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Return a JSON object.'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "\n",
    "output_parser=JsonOutputParser()\n",
    "output_parser.get_format_instructions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8bb59809",
   "metadata": {},
   "outputs": [],
   "source": [
    "### OutputParser\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "output_parser=JsonOutputParser()\n",
    "\n",
    "prompt=PromptTemplate(\n",
    "    template=\"Answer the user query \\n {format_instruction}\\n {query}\\n \",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instruction\":output_parser.get_format_instructions()},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5d612a95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['query'], input_types={}, partial_variables={'format_instruction': 'Return a JSON object.'}, template='Answer the user query \\n {format_instruction}\\n {query}\\n ')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e889a59a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'langsmith': {'description': 'LangSmith is an open-source platform for building and sharing language models.', 'features': ['Modular design for easy customization and experimentation', 'Supports various model architectures and training methods', 'Built-in tools for data preparation, training, and evaluation', 'Active community of developers and researchers', 'Accessible through a user-friendly web interface and API'], 'website': 'https://github.com/langsmithai/langsmith'}}\n"
     ]
    }
   ],
   "source": [
    "chain=prompt | model | output_parser\n",
    "response=chain.invoke({\"query\": \"can you tell me soemthing about langsmmith?\"})\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0e929449",
   "metadata": {},
   "outputs": [
    {
     "ename": "OutputParserException",
     "evalue": "Invalid json output: Let's talk about Langsmith!\n\n**Langsmith** is an open-source toolkit designed to **simplify the process of fine-tuning large language models (LLMs)**.  \n\nHere's a breakdown of what makes it special:\n\n* **User-Friendly:** Langsmith aims to make fine-tuning accessible to a wider audience, even those without extensive machine learning expertise. It provides a more intuitive and streamlined workflow compared to traditional fine-tuning methods.\n* **Flexibility:** It supports fine-tuning various popular LLMs, including:\n    * **Llama 2:** Meta's open-source LLM.\n    * **Vicuna:** A fine-tuned version of Llama 2.\n    * **GPT-NeoX:** An open-source LLM from EleutherAI.\n* **GPU Acceleration:** Langsmith leverages the power of GPUs to significantly speed up the fine-tuning process, making it more efficient.\n* **Streamlined Pipeline:** It offers a clear and structured pipeline for fine-tuning, simplifying tasks such as data preparation, model training, and evaluation.\n* **Community Driven:** Being open-source, Langsmith benefits from a vibrant community of developers and researchers who contribute to its development and support.\n\n**Key Advantages:**\n\n* **Democratization of Fine-Tuning:**  Makes it easier for individuals and organizations to customize LLMs for specific applications.\n* **Rapid Prototyping:** Allows for quick experimentation and iteration with different fine-tuning techniques.\n* **Cost-Effectiveness:** By leveraging open-source models and GPU acceleration, Langsmith can reduce the financial barriers to entry for fine-tuning.\n\n**Getting Started:**\n\nIf you're interested in exploring Langsmith, check out its official documentation and GitHub repository:\n\n* **Documentation:** https://github.com/langsmithai/langsmith/blob/main/docs/index.md\n* **GitHub:** https://github.com/langsmithai/langsmith\n\nLet me know if you have any more questions about Langsmith or any other AI topics!\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE ",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mJSONDecodeError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\hk\\agenticbatch2\\venv\\Lib\\site-packages\\langchain_core\\output_parsers\\json.py:88\u001b[39m, in \u001b[36mJsonOutputParser.parse_result\u001b[39m\u001b[34m(self, result, partial)\u001b[39m\n\u001b[32m     87\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m88\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parse_json_markdown(text)\n\u001b[32m     89\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m JSONDecodeError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\hk\\agenticbatch2\\venv\\Lib\\site-packages\\langchain_core\\utils\\json.py:150\u001b[39m, in \u001b[36mparse_json_markdown\u001b[39m\u001b[34m(json_string, parser)\u001b[39m\n\u001b[32m    149\u001b[39m     json_str = json_string \u001b[38;5;28;01mif\u001b[39;00m match \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m match.group(\u001b[32m2\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m _parse_json(json_str, parser=parser)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\hk\\agenticbatch2\\venv\\Lib\\site-packages\\langchain_core\\utils\\json.py:166\u001b[39m, in \u001b[36m_parse_json\u001b[39m\u001b[34m(json_str, parser)\u001b[39m\n\u001b[32m    165\u001b[39m \u001b[38;5;66;03m# Parse the JSON string into a Python dictionary\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m166\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m parser(json_str)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\hk\\agenticbatch2\\venv\\Lib\\site-packages\\langchain_core\\utils\\json.py:123\u001b[39m, in \u001b[36mparse_partial_json\u001b[39m\u001b[34m(s, strict)\u001b[39m\n\u001b[32m    120\u001b[39m \u001b[38;5;66;03m# If we got here, we ran out of characters to remove\u001b[39;00m\n\u001b[32m    121\u001b[39m \u001b[38;5;66;03m# and still couldn't parse the string as JSON, so return the parse error\u001b[39;00m\n\u001b[32m    122\u001b[39m \u001b[38;5;66;03m# for the original string.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m123\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m json.loads(s, strict=strict)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\hk\\agenticbatch2\\venv\\Lib\\json\\__init__.py:359\u001b[39m, in \u001b[36mloads\u001b[39m\u001b[34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[39m\n\u001b[32m    358\u001b[39m     kw[\u001b[33m'\u001b[39m\u001b[33mparse_constant\u001b[39m\u001b[33m'\u001b[39m] = parse_constant\n\u001b[32m--> \u001b[39m\u001b[32m359\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(**kw).decode(s)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\hk\\agenticbatch2\\venv\\Lib\\json\\decoder.py:345\u001b[39m, in \u001b[36mJSONDecoder.decode\u001b[39m\u001b[34m(self, s, _w)\u001b[39m\n\u001b[32m    341\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[32m    342\u001b[39m \u001b[33;03mcontaining a JSON document).\u001b[39;00m\n\u001b[32m    343\u001b[39m \n\u001b[32m    344\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m345\u001b[39m obj, end = \u001b[38;5;28mself\u001b[39m.raw_decode(s, idx=_w(s, \u001b[32m0\u001b[39m).end())\n\u001b[32m    346\u001b[39m end = _w(s, end).end()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\hk\\agenticbatch2\\venv\\Lib\\json\\decoder.py:363\u001b[39m, in \u001b[36mJSONDecoder.raw_decode\u001b[39m\u001b[34m(self, s, idx)\u001b[39m\n\u001b[32m    362\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m--> \u001b[39m\u001b[32m363\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[33m\"\u001b[39m\u001b[33mExpecting value\u001b[39m\u001b[33m\"\u001b[39m, s, err.value) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    364\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m obj, end\n",
      "\u001b[31mJSONDecodeError\u001b[39m: Expecting value: line 1 column 1 (char 0)",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mOutputParserException\u001b[39m                     Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[55]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m     10\u001b[39m output_parser = JsonOutputParser()\n\u001b[32m     11\u001b[39m chain = prompt | model | output_parser\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m response = chain.invoke({\u001b[33m\"\u001b[39m\u001b[33minput\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mcan you tell me soemthing about langsmmith?\u001b[39m\u001b[33m\"\u001b[39m})\n\u001b[32m     13\u001b[39m \u001b[38;5;28mprint\u001b[39m(response)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\hk\\agenticbatch2\\venv\\Lib\\site-packages\\langchain_core\\runnables\\base.py:3047\u001b[39m, in \u001b[36mRunnableSequence.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   3045\u001b[39m                 input_ = context.run(step.invoke, input_, config, **kwargs)\n\u001b[32m   3046\u001b[39m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3047\u001b[39m                 input_ = context.run(step.invoke, input_, config)\n\u001b[32m   3048\u001b[39m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[32m   3049\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\hk\\agenticbatch2\\venv\\Lib\\site-packages\\langchain_core\\output_parsers\\base.py:196\u001b[39m, in \u001b[36mBaseOutputParser.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    188\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    189\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    190\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    193\u001b[39m     **kwargs: Any,\n\u001b[32m    194\u001b[39m ) -> T:\n\u001b[32m    195\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28minput\u001b[39m, BaseMessage):\n\u001b[32m--> \u001b[39m\u001b[32m196\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._call_with_config(\n\u001b[32m    197\u001b[39m             \u001b[38;5;28;01mlambda\u001b[39;00m inner_input: \u001b[38;5;28mself\u001b[39m.parse_result(\n\u001b[32m    198\u001b[39m                 [ChatGeneration(message=inner_input)]\n\u001b[32m    199\u001b[39m             ),\n\u001b[32m    200\u001b[39m             \u001b[38;5;28minput\u001b[39m,\n\u001b[32m    201\u001b[39m             config,\n\u001b[32m    202\u001b[39m             run_type=\u001b[33m\"\u001b[39m\u001b[33mparser\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    203\u001b[39m         )\n\u001b[32m    204\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._call_with_config(\n\u001b[32m    205\u001b[39m         \u001b[38;5;28;01mlambda\u001b[39;00m inner_input: \u001b[38;5;28mself\u001b[39m.parse_result([Generation(text=inner_input)]),\n\u001b[32m    206\u001b[39m         \u001b[38;5;28minput\u001b[39m,\n\u001b[32m    207\u001b[39m         config,\n\u001b[32m    208\u001b[39m         run_type=\u001b[33m\"\u001b[39m\u001b[33mparser\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    209\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\hk\\agenticbatch2\\venv\\Lib\\site-packages\\langchain_core\\runnables\\base.py:1940\u001b[39m, in \u001b[36mRunnable._call_with_config\u001b[39m\u001b[34m(self, func, input_, config, run_type, serialized, **kwargs)\u001b[39m\n\u001b[32m   1936\u001b[39m     child_config = patch_config(config, callbacks=run_manager.get_child())\n\u001b[32m   1937\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(child_config) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m   1938\u001b[39m         output = cast(\n\u001b[32m   1939\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mOutput\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m-> \u001b[39m\u001b[32m1940\u001b[39m             context.run(\n\u001b[32m   1941\u001b[39m                 call_func_with_variable_args,  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[32m   1942\u001b[39m                 func,\n\u001b[32m   1943\u001b[39m                 input_,\n\u001b[32m   1944\u001b[39m                 config,\n\u001b[32m   1945\u001b[39m                 run_manager,\n\u001b[32m   1946\u001b[39m                 **kwargs,\n\u001b[32m   1947\u001b[39m             ),\n\u001b[32m   1948\u001b[39m         )\n\u001b[32m   1949\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   1950\u001b[39m     run_manager.on_chain_error(e)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\hk\\agenticbatch2\\venv\\Lib\\site-packages\\langchain_core\\runnables\\config.py:428\u001b[39m, in \u001b[36mcall_func_with_variable_args\u001b[39m\u001b[34m(func, input, config, run_manager, **kwargs)\u001b[39m\n\u001b[32m    426\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m accepts_run_manager(func):\n\u001b[32m    427\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m] = run_manager\n\u001b[32m--> \u001b[39m\u001b[32m428\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;28minput\u001b[39m, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\hk\\agenticbatch2\\venv\\Lib\\site-packages\\langchain_core\\output_parsers\\base.py:197\u001b[39m, in \u001b[36mBaseOutputParser.invoke.<locals>.<lambda>\u001b[39m\u001b[34m(inner_input)\u001b[39m\n\u001b[32m    188\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    189\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    190\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    193\u001b[39m     **kwargs: Any,\n\u001b[32m    194\u001b[39m ) -> T:\n\u001b[32m    195\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28minput\u001b[39m, BaseMessage):\n\u001b[32m    196\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._call_with_config(\n\u001b[32m--> \u001b[39m\u001b[32m197\u001b[39m             \u001b[38;5;28;01mlambda\u001b[39;00m inner_input: \u001b[38;5;28mself\u001b[39m.parse_result(\n\u001b[32m    198\u001b[39m                 [ChatGeneration(message=inner_input)]\n\u001b[32m    199\u001b[39m             ),\n\u001b[32m    200\u001b[39m             \u001b[38;5;28minput\u001b[39m,\n\u001b[32m    201\u001b[39m             config,\n\u001b[32m    202\u001b[39m             run_type=\u001b[33m\"\u001b[39m\u001b[33mparser\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    203\u001b[39m         )\n\u001b[32m    204\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._call_with_config(\n\u001b[32m    205\u001b[39m         \u001b[38;5;28;01mlambda\u001b[39;00m inner_input: \u001b[38;5;28mself\u001b[39m.parse_result([Generation(text=inner_input)]),\n\u001b[32m    206\u001b[39m         \u001b[38;5;28minput\u001b[39m,\n\u001b[32m    207\u001b[39m         config,\n\u001b[32m    208\u001b[39m         run_type=\u001b[33m\"\u001b[39m\u001b[33mparser\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    209\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\hk\\agenticbatch2\\venv\\Lib\\site-packages\\langchain_core\\output_parsers\\json.py:91\u001b[39m, in \u001b[36mJsonOutputParser.parse_result\u001b[39m\u001b[34m(self, result, partial)\u001b[39m\n\u001b[32m     89\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m JSONDecodeError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     90\u001b[39m     msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mInvalid json output: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtext\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m91\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m OutputParserException(msg, llm_output=text) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n",
      "\u001b[31mOutputParserException\u001b[39m: Invalid json output: Let's talk about Langsmith!\n\n**Langsmith** is an open-source toolkit designed to **simplify the process of fine-tuning large language models (LLMs)**.  \n\nHere's a breakdown of what makes it special:\n\n* **User-Friendly:** Langsmith aims to make fine-tuning accessible to a wider audience, even those without extensive machine learning expertise. It provides a more intuitive and streamlined workflow compared to traditional fine-tuning methods.\n* **Flexibility:** It supports fine-tuning various popular LLMs, including:\n    * **Llama 2:** Meta's open-source LLM.\n    * **Vicuna:** A fine-tuned version of Llama 2.\n    * **GPT-NeoX:** An open-source LLM from EleutherAI.\n* **GPU Acceleration:** Langsmith leverages the power of GPUs to significantly speed up the fine-tuning process, making it more efficient.\n* **Streamlined Pipeline:** It offers a clear and structured pipeline for fine-tuning, simplifying tasks such as data preparation, model training, and evaluation.\n* **Community Driven:** Being open-source, Langsmith benefits from a vibrant community of developers and researchers who contribute to its development and support.\n\n**Key Advantages:**\n\n* **Democratization of Fine-Tuning:**  Makes it easier for individuals and organizations to customize LLMs for specific applications.\n* **Rapid Prototyping:** Allows for quick experimentation and iteration with different fine-tuning techniques.\n* **Cost-Effectiveness:** By leveraging open-source models and GPU acceleration, Langsmith can reduce the financial barriers to entry for fine-tuning.\n\n**Getting Started:**\n\nIf you're interested in exploring Langsmith, check out its official documentation and GitHub repository:\n\n* **Documentation:** https://github.com/langsmithai/langsmith/blob/main/docs/index.md\n* **GitHub:** https://github.com/langsmithai/langsmith\n\nLet me know if you have any more questions about Langsmith or any other AI topics!\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE "
     ]
    }
   ],
   "source": [
    "# Assignment JSON output parser with ChatPromptTemplate\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are an expert AI engineer. Provide me answer based on the question.\"),\n",
    "        (\"user\", \"{input}\")\n",
    "    ]\n",
    ")   \n",
    "output_parser = JsonOutputParser()\n",
    "chain = prompt | model | output_parser\n",
    "response = chain.invoke({\"input\": \"can you tell me soemthing about langsmmith?\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "80eff1ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are an expert AI Engineer.Provide the response in json.Provide me answer based on the question'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#json Output with ChatPromptTemplate\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt=ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\"You are an expert AI Engineer.Provide the response in json.Provide me answer based on the question\"),\n",
    "        (\"user\",\"{input}\")\n",
    "    ]\n",
    ")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "21db5548",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': \"Langsmith is an open-source platform designed to simplify the development and deployment of language models. \\n\\n  Here's a breakdown of its key features and benefits:\\n\\n  * **Streamlined Development:** Langsmith provides a user-friendly interface and tools that make it easier to experiment with and fine-tune language models.\\n\\n  * **Modular Architecture:** Its modular design allows users to easily swap out components, customize workflows, and integrate with existing tools.\\n\\n  * **Open and Extensible:** Being open-source, Langsmith encourages community contributions, fostering innovation and collaboration.\\n\\n  * **Cloud-Native:** It's built to be cloud-compatible, enabling scalability and efficient resource utilization.\\n  * **Focus on Accessibility:** Langsmith aims to make advanced AI techniques more accessible to a wider range of developers and researchers.\\n\\n  **In essence, Langsmith empowers individuals and teams to leverage the power of language models without requiring extensive technical expertise.**\"}\n"
     ]
    }
   ],
   "source": [
    "chain=prompt|model|output_parser\n",
    "response=chain.invoke({\"input\":\"Can you tell me about Langsmith?\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "a634ea57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='<response><answer>LangChain is an open-source framework designed to simplify the development of applications powered by large language models (LLMs). It provides a set of tools and components that allow developers to easily integrate LLMs into their workflows, chain them together to create complex functionalities, and manage their interactions with external data sources.</answer></response>\\n' additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 73, 'prompt_tokens': 39, 'total_tokens': 112, 'completion_time': 0.132727273, 'prompt_time': 0.004000673, 'queue_time': 0.5415014330000001, 'total_time': 0.136727946}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None} id='run--93bd57b0-c3cf-4ed9-8324-47773d236533-0' usage_metadata={'input_tokens': 39, 'output_tokens': 73, 'total_tokens': 112}\n"
     ]
    }
   ],
   "source": [
    "#XML Output Parser with ChatPromptTemplate\n",
    "from langchain.output_parsers.xml import XMLOutputParser\n",
    "\n",
    "# XML Output Parser with ChatPromptTemplate\n",
    "output_parser = XMLOutputParser()\n",
    "\n",
    "# Prompt that instructs the model to return XML\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful assistant. Respond in this XML format: <response><answer>Your answer here</answer></response>\"),\n",
    "    (\"human\", \"{input}\")\n",
    "])\n",
    "\n",
    "# Build the chain\n",
    "chain = prompt | model\n",
    "\n",
    "response =chain.invoke({\"input\": \"What is LangChain?\"})\n",
    "\n",
    "# Print result\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "cc20b8f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'description': 'Langsmith is an open-source platform developed by AI21 Labs for building and deploying AI applications.', 'key_features': ['**No-code interface:** Allows users to create AI applications without writing code.', '**Modular design:** Enables developers to easily integrate different AI components.', '**Customization:** Provides options for fine-tuning and customizing AI models.', '**MLOps capabilities:** Offers tools for managing and deploying AI models.', '**Community-driven:**  Benefits from contributions and support from the open-source community.'], 'use_cases': ['Chatbots and conversational AI', 'Text summarization and generation', 'Code generation and completion', 'Data analysis and insights', 'Personalized learning experiences'], 'benefits': ['**Faster development:** Streamlines the process of building AI applications.', '**Reduced costs:**  Eliminates the need for extensive coding expertise.', '**Increased accessibility:** Makes AI technology accessible to a wider audience.', '**Enhanced collaboration:**  Facilitates teamwork and knowledge sharing.', '**Improved innovation:**  Empowers developers to experiment with new AI ideas.'], 'link': 'https://www.langsmith.ai/'}\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "4d434024",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are an expert AI engineer. Provide the repsonse in json. Provide me answer based on the question.'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "output_parser = JsonOutputParser()\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are an expert AI engineer. Provide the repsonse in json. Provide me answer based on the question.\"),\n",
    "        (\"user\", \"{input}\")\n",
    "    ]\n",
    ")\n",
    "prompt\n",
    "\n",
    "chain= prompt | model | output_parser\n",
    "response = chain.invoke({\"input\": \"Can you tell me about Langsmith?\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "538d30d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='```xml\\n<response>\\n  <information>\\n    <name>Langsmith</name>\\n    <description>Langsmith is an open-source platform for developing and deploying language models.</description>\\n    <features>\\n      <feature>Modular design allows for easy customization and extensibility.</feature>\\n      <feature>Supports various programming languages and frameworks.</feature>\\n      <feature>Provides tools for training, evaluating, and deploying models.</feature>\\n    </features>\\n    <developer>\\n      <organization>Hugging Face</organization>\\n    </developer>\\n  </information>\\n</response>\\n```' additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 136, 'prompt_tokens': 195, 'total_tokens': 331, 'completion_time': 0.247272727, 'prompt_time': 0.007830087, 'queue_time': 0.16576193099999997, 'total_time': 0.255102814}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None} id='run--16e24037-2b49-4b3d-81b4-55319cdde6ff-0' usage_metadata={'input_tokens': 195, 'output_tokens': 136, 'total_tokens': 331}\n"
     ]
    }
   ],
   "source": [
    "### XML OutputParser with PrmptTemplate\n",
    "\n",
    "from langchain_core.output_parsers import XMLOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "output_parser=XMLOutputParser()\n",
    "\n",
    "prompt=PromptTemplate(\n",
    "    template=\"Answer the user query \\n {format_instruction}\\n {query}\\n \",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instruction\":output_parser.get_format_instructions()},\n",
    ")\n",
    "prompt\n",
    "\n",
    "chain=prompt|model\n",
    "response=chain.invoke({\"query\":\"Can you tell me about Langsmith?\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "11adbb07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'setup': \"Why couldn't the bicycle stand up by itself?\",\n",
       " 'punchline': 'Because it was two tired.'}"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## With Pydantic\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "model = ChatOpenAI(temperature=0.7)\n",
    "\n",
    "# Define your desired data structure.\n",
    "class Joke(BaseModel):\n",
    "    setup: str = Field(description=\"question to set up a joke\")\n",
    "    punchline: str = Field(description=\"answer to resolve the joke\")\n",
    "\n",
    "\n",
    "# And a query intented to prompt a language model to populate the data structure.\n",
    "joke_query = \"Tell me a joke.\"\n",
    "\n",
    "# Set up a parser + inject instructions into the prompt template.\n",
    "parser = JsonOutputParser(pydantic_object=Joke)\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"Answer the user query.\\n{format_instructions}\\n{query}\\n\",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "chain = prompt | model | parser\n",
    "\n",
    "chain.invoke({\"query\": joke_query})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "e4092152",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'joke': \"Why couldn't the bicycle stand up by itself? It was two tired!\"}"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Without Pydantic\n",
    "joke_query = \"Tell me a joke .\"\n",
    "\n",
    "parser = JsonOutputParser()\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"Answer the user query.\\n{format_instructions}\\n{query}\\n\",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "chain = prompt | model | parser\n",
    "\n",
    "chain.invoke({\"query\": joke_query})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "926ccc68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<movie>Big</movie>\n",
      "<movie>Forrest Gump</movie>\n",
      "<movie>Philadelphia</movie>\n",
      "<movie>Saving Private Ryan</movie>\n",
      "<movie>Cast Away</movie>\n",
      "<movie>The Green Mile</movie>\n",
      "<movie>Toy Story</movie>\n",
      "<movie>Apollo 13</movie>\n",
      "<movie>Sully</movie>\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import XMLOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "\n",
    "actor_query = \"Generate the shortened filmography for Tom Hanks.\"\n",
    "\n",
    "output = model.invoke(\n",
    "    f\"\"\"{actor_query}\n",
    "Please enclose the movies in <movie></movie> tags\"\"\"\n",
    ")\n",
    "\n",
    "print(output.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "5527a645",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Joke(setup=\"Why don't scientists trust atoms?\", punchline='Because they make up everything!')"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.output_parsers import YamlOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "# Define your desired data structure.\n",
    "class Joke(BaseModel):\n",
    "    setup: str = Field(description=\"question to set up a joke\")\n",
    "    punchline: str = Field(description=\"answer to resolve the joke\")\n",
    "\n",
    "\n",
    "model = ChatOpenAI(temperature=0.5)\n",
    "\n",
    "# And a query intented to prompt a language model to populate the data structure.\n",
    "joke_query = \"Tell me a joke.\"\n",
    "\n",
    "# Set up a parser + inject instructions into the prompt template.\n",
    "parser = YamlOutputParser(pydantic_object=Joke)\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"Answer the user query.\\n{format_instructions}\\n{query}\\n\",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "chain = prompt | model | parser\n",
    "\n",
    "chain.invoke({\"query\": joke_query})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe7deca",
   "metadata": {},
   "source": [
    "### Assisgment:\n",
    "Create a simple assistant that uses any LLM and should be pydantic, when we ask about any product it should give you two information product Name, product details tentative price in USD (integer). use chat Prompt Template."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "c73c1f8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'product_name': 'iPhone 13 Pro', 'details': 'The iPhone 13 Pro features a Super Retina XDR display, A15 Bionic chip, Pro camera system with 3x optical zoom, up to 1TB of storage, Ceramic Shield front cover, 5G capable, and improved battery life.', 'price_usd': 999}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "# Define your desired data structure to get product name, prodcut details and tentative price in USD\n",
    "class Product(BaseModel):\n",
    "    name: str = Field(description=\"Name of the product\")\n",
    "    details: str = Field(description=\"Details about the product\")\n",
    "    price_usd: float = Field(description=\"Tentative price in USD\")\n",
    "\n",
    "model = ChatOpenAI(temperature=0.5)\n",
    "# And a query intended to prompt a language model to populate the data structure.\n",
    "product_query = \"What is the latest iPhone model and its features?\"\n",
    "# Set up a parser + inject instructions into the prompt template.\n",
    "parser = JsonOutputParser(pydantic_object=Product)\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are an expert product analyst. Always provide the product name, details, and a tentative price in USD (as a number) in JSON format.\"),\n",
    "        (\"user\", \"{input}\")\n",
    "    ]\n",
    ")\n",
    "chain = prompt | model | parser\n",
    "response = chain.invoke({\"input\": product_query})\n",
    "print(response)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7186d672",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
